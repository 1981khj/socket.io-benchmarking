<!DOCTYPE html>
<html>
<head>
  <meta charset='utf-8'>

  <title>drewww/socket.io-benchmarking @ GitHub</title>

  <style type="text/css">
    body {
      margin-top: 1.0em;
      background-color: #ffffff;
      font-family: Helvetica, Arial, FreeSans, san-serif;
      color: #0A0A10;
    }
    #container {
      margin: 0 auto;
      width: 700px;
    }
    h1 { font-size: 3.8em; color: #1B497F; margin-bottom: 3px; }
    h1 .small { font-size: 0.4em; }
    h1 a { text-decoration: none }
    h2 { font-size: 1.5em; color: #1B497F; }
    h3 { text-align: center; color: #1B497F; }
    a { color: #1B497F; }
    .description { font-size: 1.2em; margin-bottom: 30px; margin-top: 30px; font-style: italic;}
    .download { float: right; }
    pre { background: #000; color: #fff; padding: 15px; font-family: Consolas, Menlo, Monaco, Lucida Console,}

	span.inline { background: #eee; color: #0A0A10; border: 1px solid #dfdfdf; padding: 0px; display:inline; margin: 0px; font-family: Consolas, Menlo, Monaco, Lucida Console;}

    hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    .footer { text-align:center; padding-top:30px; font-style: italic; }
  </style>
</head>

<body>
  <a href="https://github.com/drewww/socket.io-benchmarking"><img style="position: absolute; top: 0; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub" /></a>

  <div id="container">

    <h1><a href="https://github.com/drewww/socket.io-benchmarking">Practical socket.io Benchmarking</a>
      <span class="small"><a href="http://web.media.mit.edu/~dharry/">Drew Harry</a></span></h1>


	<p>

    <p>I've had lots of fun making prototypes in <a href="http://nodejs.org">nodejs</a> with <a href="http://http://socket.io/">socket.io</a>. But I've kinda felt lost in thinking about the performance of the server if I ever needed to scale something up. What, exactly, is costly? What's the bottleneck in performance? A few potential limiting factors came to mind:</p>

<ul>
	<li>holding lots of connections open simultaneously</li>
	<li>receiving lots of messages</li>
	<li>sending lots of messages</li>
</ul>

<p>There's been some nice work at figuring out how many connections <a href="http://blog.mixu.net/2011/11/22/performance-benchmarking-socket-io-0-8-7-0-7-11-and-0-6-17-and-nodes-native-tcp/">a server might be able to support</a>, but that only knocks out one of our potential bottlenecks. How do we figure out whether holding simultaneous connections open is the most intensive part of scaling up a <span class="inline">socket.io</span> server? And if the bottleneck is message-related, what's a good rule of thumb for when you're going to need to move beyond a single-process model to scale up?</p>

<p>I'm going to be looking primarily at the cost to sending messages, not the cost of receiving messages. My instinct is that the vast majority of <span class="inline">socket.io</span> applications will have access patterns that involve a lot more sending than receiving, so this is a reasonable focus. In my case, I was interested in chat systems, but even in other data-oriented systems I suspect sending will outweigh receiving by a substantial amount.</p>

<p>This is not a comparative analysis. I'm not trying to argue that <span class="inline">node</span> or <span class="inline">socket.io</span> are better or worse than some other technique (although I will muse on the tradeoffs at the end of the piece), simply trying to give people architecting <span class="inline">socket.io</span> applications a sense of when they might start hitting limits and what the behavior is when you're close to the limit. I should also say that I'm not a veteran <span class="inline">node</span> programmer, so I apologize if there are any glaring mistakes or I'm making arguments that are already obvious to everyone. They weren't obvious to me starting out, and I had a hard time finding the information I wanted elsewhere, so here I am.</p>

<p><b>TL;DR</b> If you want to bypass the full analysis, heres the punchline: the main performance bottleneck in most applications is going to be <i>sending</i> messages, not holding connections open or receiving messages. On a 3.3 MHz Xeon X5470 using one core, the max messages-sent-per-second rate is around 9,000&ndash;10,000 depending on the concurrency level.</p>
	
<h2>Testing Framework</h2>

<p> The testing setup is pretty simple, but is worth a quick description. The server is the worlds' most simple server. It's an echo-broadcast server: whenever it receives a message, it broadcasts that message to every connected client.</p>

<p>The client is a little more complicated, but not much. The main metric it collects is the time that elapses between when it sends a message to the server and when it receives that message back in its broadcasted form. The client gathers the mean response times across a range of concurrency levels and message sending rates, which forms the data set for the analysis below. If the server ever drops a connection (which happens at high loads - more on this later) or it takes longer than five seconds for all the sent-messages to be received after sending stops, then the test is over for that concurrency level. The client is written in Java, using <a href="https://github.com/TooTallNate/Java-WebSocket">this websocket implementation</a>. I tried writing the test client in <span class="inline">node</span> and <span class="inline">python</span>, but couldn't get the performance I needed at high concurrency states in a single process.</p>

<h2>Results</h2>

<p>All the graphs in this section come from the same data set. The server was running on an Ubuntu VM using one core of a 3.3 MHz Xeon X5470 in a data center here at the <a href="http://media.mit.edu/">MIT Media Lab</a>. The computer running the test client was a beastly OS X that was sufficiently powerful that the client was never performance limited.</p>

<p>Alright, so lets start by looking at what these response time curves look like. When looking at these, it's important to remember that any response time greater than 100-200ms represents a basically fatal situation; what we're interested in here is at what load levels (concurrency, message rates) we start to see slowdown. Once the server event queue starts to jam and we see delays, the writing is on the wall for the server instance.</p>

<img width="100%" src="img/received-per-second.png">

<p>On the X axis of this graph, we're measuring messages <i>received</i> by the server per second across a range of concurrency levels. Each line is a different concurrency level; low concurrency lines are darker, high concurrency is lighter. The Y axis is mean roundtrip time for messagesYou can see the onset of serious performance problems occurs at much lower message reception rates as concurrency increases. This makes sense because for every message we receive we're sending a message to ever connected client, so if sends are even a little expensive, we can quickly jam the event loop.</p>

<p>So lets massage the data and change the X axis to be message <i>sent</i> by the server instead of messages <i>received</i>. Because every messages we receive gets broadcasted, we can just multiply messages received by the concurrency level.</p>

<img width="100%" src="img/sent-per-second.png">


<p>That's more like it. When we shift to messages <i>sent</i> per second the different concurrency levels align nicely. No matter your concurrency level, there appears to be a relatively hard limit between 9,000 and 10,000 messages sent per second. (It looks like the concurrency-25 jams earlier, but that's an artifact that takes too much time to explain. It's not really failing at that point.)</p>

<p>The last aspect I want to poke at is behavior below the jamming threshold. Lets switch to a logarithmic Y axis and see how it looks.</p>

<img width="100%" src="img/sent-per-second-log.png">

<p>I want to focus your attention on the pre-jamming part of this graph. What we can see here is that higher concurrency levels <i>do</i> add load to the server. When you're at a concurrency level of 1,000, mean roundtrip times are always longer than when you're at lower concurrency levels and you do jam slightly sooner. This different is not that dramatic, though. Even at 1,000 concurrency, mean roundtrip times are on the order of 100ms. That's not amazing, but it's certainly manageable and it stays pretty much constant until you hit the jamming threshold. </p>

<h2>Analysis</h2>
	
<p>There's been a lot of conversation about the relative performance of single-threaded versus multiple-threaded applications. I'm not doing a direct comparison here, but nonetheless I think there are some interesting lessons.</p>

<p>In a single-threaded environment like <span class="inline">node</span>, scheduling tasks is handled with an event queue. Tasks are pushed onto the queue and executed (it seems) more or less in the order they're added. When we start to see rising roundtrip times, it means we've started adding more tasks onto the queue than can be processed in a second. I've been calling that phase "jamming." Once you hit that point, performance is going to very rapidly degrade until the rate of new tasks falls below the jamming threshold. Even then, it'll take a while to clear out the queue and get back to acceptable performance. Perhaps even more troubling, when the queue is being jammed, <span class="inline">setTimeout</span> seems to stop working reliably; you can schedule a task 1000ms into the future but if the queue is jammed that task seems to wait more or less until the queue clears.<p>

<p>This is not necessarily all bad news. It's not like a multi-threaded model performs way better if you're asking the CPU to do more work per second than it can. Both modes fail in problematic ways. But in very high load situations with multiple threads, the scheduler at least has the ability to schedule high priority threads that might be able to more effectively recover from the situation, while in <span class="inline">node</span> I'm not really sure what I can do.</p>

<p>On the plus side, performance in non-jammed situations is superb. Up until you jam, you can send even relatively large amounts of messages very quickly. In practice, you probably want your application to be well below the jamming limit because recovering can be difficult.</p>

<p>The task queue also explains why we see longer roundtrip times at higher concurrency levels, even at very low messaging rates. There seems to be a certain amount of periodic CPU overhead to keeping sockets open that needs to happen more or less all the time. If a bunch those tasks are queued up when a message arrives, it's not going to get processed until socket upkeep is done. This pushes up mean roundtrip times. Really, any periodic task your system needs to do (and most systems will have something in this category) will have a similar effect on your baseline roundtrip performance; below the jamming threshold, mean roundtrip times seem to me to be a reasonable measure of how full the task queue tends to be. Above the jamming threshold, these periodic tasks simply don't get processed in time. In <span class="inline">socket.io</span>'s case, if you jam the server, it will start dropping connections indiscriminately because it can't get its periodic upkeep executed in time.</p>

<h2>So What?</h2>

<p>Ultimately, I spent a bunch of time figuring this out because I wanted to ask a very practical question: Where should I focus my optimization efforts? It's clear to me now that I have to be cautious with how often I use <span class="inline">io.sockets.emit</span> or <span class="inline">io.sockets.in</span>. If I want to be able to support 5,000 concurrent users, a broadcast every second will use up basically half of my messaging capacity. If I have a chat room with 200 people in it sending a message a second on average, that's only about 2% of my capacity.</p>

<p>When you do need to start scaling, this also suggests a plan of attack. You can split off a thin communication layer that keeps sockets open for you and handles sending and receiving and isolate a huge amount of the load. With a load balancer you can spin up a bunch of these instances (even on the same box - one per core) and connect everything up with something like <a href="http://www.rabbitmq.com/">rabbitMQ</a>. Then just replace your calls to <span class="inline">emit</span> with something that talks to the messaging queue and you should be set. By keeping all the socket-handling work off the main logic core, you can avoid doing any trickier work like partitioning your actual logic until later.</p>

<p>This is all speculative, though. I haven't actually written that part of the system yet, but based on this data it seems to me like a reasonable strategy.</p>
	
<h2>Open Questions</h2>
Dependency on message size, comparison to lower-level protocols, measuring sending versus receiving...?

<h2>Acknowledgments</h2>

Many thanks to <a href="http://tirl.org/">Charlie DeTar</a> and <a href="https://twitter.com/#!/jonchambers">Jon Chambers</a> for their help in thinking about this problem! Couldn't have done it without them.

	
	
<!-- <p>This whole adventure was motivated by trying to figure out if a <a href="http://roar.media.mit.edu/">prototype large-scale chat system</a> I'd been working on was going to need to be radically re-architected to scale it up for events with 5,000 to 10,000 people. So I was particularly concerned with message sending rates. How expensive would it be to broadcast a message to every connected user?</p>


<p>	As I was trying to evaluate the performance of a prototype for a <a href="http://roar.media.mit.edu">new project of mine</a> I was having a hard time figuring out what exactly the bottlenecks in my system were going to be. There's been some nice work in this space already, Peter Griess has a handy tool called <a href="http://blog.std.in/2010/09/24/benchmarking-web-socket-servers/">wsbench</a> </p>
     -->

    

    

    
    

    <h2>Download</h2>
    <p>
		All the code I used to generate this data is available in the github repository. It's not particularly useable or well documented, but it did work long enough for me to collect the data. Please let me know if you discover any egregious oversights in the methodology that the code reveals and I'll update this article accordingly. You can download the whole repository in either 
      <a href="https://github.com/drewww/socket.io-benchmarking/zipball/master">zip</a> or
      <a href="https://github.com/drewww/socket.io-benchmarking/tarball/master">tar formats.
    </p>
    <p>You can also clone the project with <a href="http://git-scm.com">Git</a>
      by running:
      <pre>$ git clone git://github.com/drewww/socket.io-benchmarking</pre>

	I would of course be deeply grateful for any updates or edits to the code. It might be worth turning the core client-side tester into a general purpose socket.io load testing tool aimed for practical, real-life use patterns at high concurrency. 
    </p>
	

  </div>

<script type=\"text/javascript\">
var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\");
document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\"));
</script>
<script type=\"text/javascript\">
try {
var pageTracker = _gat._getTracker("UA-841537-7");
pageTracker._trackPageview();
} catch(err) {}</script>"
</body>
</html>
